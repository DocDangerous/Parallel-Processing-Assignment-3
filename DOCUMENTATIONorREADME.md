# Parallel-Processing-Assignment-3

//INSTRUCTIONS To compile and run it from the terminal, first download it to your directory of choice then navigate there with the cd command. With g++ installed, run the command "g++ -o Assignment3 Assignment3.cpp" to compile the program. Then just type "Assignment3.exe" to run it.

//PROBLEM 1 DESIGN APPROACH Honestly, I ran out of time with problem 1. Initially, I tried to import the "validate" methodology into the linked list. However, I ran into trouble in the case where two neighboring nodes are waiting on each other to become available for use. I had the idea of a queue system for each node, where when validating a node and its neighbors, a thread would check if those nodes were owned by a thread currently waiting in the queue of the node the first thread owned, and if so, choose some default "solver" to decide who gets ownership. However, this was just too complicated, every class seemed to make everything due this week, and I had my Senior Design stuff finish this week as well, so I had to pick my battles. I ended up just having one mutex around the whole linked list, while also having other arrays/vectors with different mutexes to allow some parallelism. Insertion (and consequently sorting) was done via linear list traversal from the head, but removal WAS supposed to be O(1) by getting the Gift pointer at the gift array index equal to the id of the gift, but I couldn't figure out a fast system to randomly select a node to delete from the list. I could just randomly generate a number from 0 - 500,000 until I get one that's on the list, but I question if that's even faster. So the current thing generates an index between 0 and the size of the linked list, and then traverses that distance and removes the gift at that index. All in all I couldn't really get it to actually run, I'm sure it's something weird with the pointers, a misplaced & or * somewhere, I don't know. I just didn't have time and I'm burnt out.

//PROBLEM 2 DESIGN APPROACH This one I could finish, but I'd be lying if I said I fully understood the assignment's phrasing. As is, every thread just iterates from 0 to 59, "collecting data" for each "minute," packing it an array (as well as keeping a max heap to track the record values), and quickly passing those references to the a global "report" instance. The instance takes in the data and stores it, allowing each thread to resume recording. The idea was to simulate each thread operating as independently as possible whilst having as little downtime passing data as needed. The report instance passes the first 5 values of each max heap into its own max heap, leaving a grand record of the 5 total highest temps, and then pops each heap to the last 5 before passing those to its own min heap to collect the 5 coldest. For the interval tracking, I'm just gonna copy-paste my comment in the code: For each ten minute interval in the data, get the largest and smallest temperature among each thread's entry for that minute, and compare it against the respective largest and smallest temperature 10 minutes later. The greatest absolute difference between the two is saved and compared against the running lead.
